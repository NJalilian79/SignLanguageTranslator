import cv2
from cvzone.HandTrackingModule import HandDetector
from cvzone.ClassificationModule import Classifier
import numpy as np
import math

cap = cv2.VideoCapture(0)
detector = HandDetector(maxHands=1)
Classifier = Classifier("Model/Keras_model.h5", "Model/labels.txt")
offset = 20
imgsize = 300
counter = 0
labels = ["A", "B", "C"]
while True:
    success, img = cap.read()
    imgoutput = img.copy()
    hands, img = detector.findHands(img)
    if hands:
        hand = hands[0]
        x, y, w, h = hand['bbox']
        imgwhite = np.ones((imgsize, imgsize, 3), np.uint8)*255
        imgcrop = img[y-offset:y + h+offset, x-offset:x + w+offset]
        imgcropshape = imgcrop.shape

        aspectratio = h/w
        if aspectratio >1:
            k = imgsize/h
            wcal = math.ceil(k*w)
            imgresize = cv2.resize(imgcrop,(wcal, imgsize))
            imgresizeshape = imgcrop.shape
            wgap = math.ceil((imgsize-wcal)/2)
            imgwhite[:, wgap:wcal+wgap] = imgresize
            prediction, index = Classifier.getPrediction(imgwhite, draw=False)
            print(prediction, index)
        
        else:
            k = imgsize/w
            hcal = math.ceil(k*h)
            imgresize = cv2.resize(imgcrop,(imgsize, hcal))
            imgresizeshape = imgresize.shape
            hgap = math.ceil((imgsize - hcal)/2)
            imgwhite[hgap:hcal + hgap, :] = imgresize
            prediction, index = Classifier.getPrediction(imgwhite, draw=False)
        cv2.rectangle(imgoutput, (x-offset,y-offset-50), (x-offset+90, y-offset-50+50), (255, 0, 255), 4)    
        cv2.putText(imgoutput, labels[index], (x, y-26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 0, 255), 2)
        cv2.rectangle(imgoutput, (x-offset,y-offset), (x+w+offset, y+h+offset), (255, 0, 255), 4)
        

        cv2.imshow("imagecrop", imgcrop)
        cv2.imshow("imagewhite", imgwhite)

    cv2.imshow("image", imgoutput)
    cv2.waitKey(1)
    